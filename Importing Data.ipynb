{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Opening Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What should I remember? Suits\n"
     ]
    }
   ],
   "source": [
    "# Create a context manager\n",
    "\n",
    "def remember(thing):\n",
    "    with open('someText.txt', 'a') as file: # 'a' is a flag to append to the newly created file...also 'w', and 'r'\n",
    "        file.write(thing + '\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    remember(input('What should I remember?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apples\\nCoa'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someFile = open('someText.txt')\n",
    "someFile.read(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apples\\nCoats\\nBoats\\nSuits\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someFile.seek(0)\n",
    "someFile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apples\\n', 'Coats\\n', 'Boats\\n', 'Suits\\n']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "someFile.seek(0)\n",
    "lines = someFile.readlines()\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(path, mode = 'r') #r=read, w=write\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "print(file.closed) #will print True or False to ensure file is closed\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To automatically close the file use a Context Manager\n",
    "path = 'path'\n",
    "with open(path, 'r') as file:\n",
    "    print(file.read())\n",
    "    \n",
    "print(file.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print a fewlines at a time\n",
    "path = 'path'\n",
    "with open(path) as file:\n",
    "    print(file.readline())\n",
    "\n",
    "print(file.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving files\n",
    "df.to_csv('new file name')\n",
    "df.to_excel('new file name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Flat Files using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt(path, delimiter=',', dtype=str, skiprows=1, usecols=[0,2,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing mixed data types using numpy\n",
    "np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\n",
    "np.recfromcsv('titanic.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "#Turn into numpy array\n",
    "data_array = df.column.values\n",
    "print(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Excel file\n",
    "import panda as pd\n",
    "file = 'file_name.xlsx'\n",
    "data = pd.ExcelFile(file)\n",
    "\n",
    "print(data.sheet_names) #to print out sheets in a workbook\n",
    "df = data.parse('sheet_name') #import the sheets by name or index\n",
    "df = data.parse(0, parse_cols=[0], skiprows=[0], names=['Renamed Column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing Stata files\n",
    "import pandas as pd\n",
    "data = pd.read_stata('file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing MATLAB files\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat(filename)\n",
    "\n",
    "#mat objects are dictionaries...keys=variable names, \n",
    "#values = objects assigned to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pickle package\n",
    "import pickle\n",
    "\n",
    "with open('data.pkl', 'rb') as file:\n",
    "    d = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing SAS files using pandas\n",
    "import pandas as pd\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "with SAS7BDAT('file_name') as file:\n",
    "    variable = file.to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing HDF5...can scale to exabytes and is hirearchical \n",
    "import h5py\n",
    "data = h5py.File(path, 'r')\n",
    "\n",
    "#groups in hdf5\n",
    "for key in data.keys():\n",
    "    print(key)\n",
    "     \n",
    "#subgroups\n",
    "for key in data['group'].keys():\n",
    "    print(key)\n",
    "    \n",
    "#values\n",
    "print(data['group']['subgroup'].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Relational Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///file_name')\n",
    "\n",
    "#to view tables\n",
    "tables = engine.table_names()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Querying relational databases in Python\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///file_name')\n",
    "con = engine.connect()\n",
    "rs = con.execute('SELECT * FROM orders')\n",
    "df = pd.DataFrames(rs.fetchall())\n",
    "df.columns = rs.keys()\n",
    "con.close()\n",
    "print(df.head())\n",
    "\n",
    "#or using context manager\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///file_name')\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute('SELECT * FROM orders') #WHERE, ORDER BY, INNER JOIN...filter search\n",
    "    df = pd.DataFrames(rs.fetchall()) #fetchmany(5) #amount of rows\n",
    "    df.columns = rs.keys() #custom column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying relational databases directly with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('sqlite:///file_name')\n",
    "df = pd.read_sql_query('SELECT * FROM Orders', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download file \n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "urlretrieve = (url, 'winequality-white.csv' )\n",
    "print(urlretrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HTTP Requests to import files from the web using urllib\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "url = 'http://wikipedia.org/'\n",
    "request = Request(url)\n",
    "response = urlopen(request)\n",
    "html = response.read()\n",
    "respinse.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HTTP Requests to import files from the web using Requests package\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'http://wikipedia.org/'\n",
    "request = requests.get(url)\n",
    "text = request.text\n",
    "\n",
    "formatted = BeautifulSoup(text)\n",
    "pretty = formatted.prettify()\n",
    "print(pretty)\n",
    "\n",
    "for link in formatted.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading JSON in Python\n",
    "import json\n",
    "\n",
    "with open('file.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    \n",
    "for key, value in json_data.items():\n",
    "    print(key + ':' + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to an API\n",
    "import requests\n",
    "\n",
    "url = 'http://omdbapi.com/?t=hackers'\n",
    "content = requests.get(url)\n",
    "json_data = content.json()\n",
    "for key, value in json_data.items():\n",
    "    print(key + ':' + value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
